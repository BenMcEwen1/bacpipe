## MAIN VARS ##

# PATHS:
# define paths for your data, these are the standard directories, if you 
# used the file condenser. If you do not have annotated data, and all of your
# sound files are in one directory, change accordingly
audio_dir :       "bacpipe/evaluation/datasets/audio_test_files"




# CHOOSE FROM MODELS
models : [
    "animal2vec_xc",
    "animal2vec_mk",
    "audiomae",
    "aves",
    "biolingual",
    "birdaves",
    "birdnet",
    "avesecho_passt",
    "hbdet",
    "insect66",
    "mix2",
    "perch",
    "protoclr",
    "rcl_fs_bsed",
    "surfperch",
    "whaleperch",
    "vggish",
  ]


# embedding model name
embedding_model: ["perch", "surfperch", "whaleperch"]

# dimensionality reduction model name.
supported_models: [
  "umap"
]
dim_reduction_model: None